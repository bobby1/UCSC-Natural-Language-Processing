{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5cbc5a8-6c62-42fe-83da-43c1806c7885",
   "metadata": {},
   "source": [
    "### AISV_801 Natural Language Processing ###\n",
    "#### Instructor Joseph Meyer #### \n",
    "Lab7: Fine tune an LLM on a custom dataset\n",
    "        Helper script\n",
    "        Letâ€™s start witht lamini\n",
    "        https://huggingface.co/MBZUAI/LaMini-Cerebras-590M\n",
    "        Use the guanaco dataset\n",
    "        https://huggingface.co/datasets/timdettmers/openassistant-guanaco\n",
    "\n",
    "Bobby Wen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ef9a412-bb16-440d-9dd4-4b5a13be85d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xformers in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (0.0.21)\n",
      "Requirement already satisfied: numpy in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from xformers) (1.25.0)\n",
      "Requirement already satisfied: torch==2.0.1 in c:\\users\\b1\\appdata\\roaming\\python\\python310\\site-packages (from xformers) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch==2.0.1->xformers) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch==2.0.1->xformers) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch==2.0.1->xformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch==2.0.1->xformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch==2.0.1->xformers) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from jinja2->torch==2.0.1->xformers) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from sympy->torch==2.0.1->xformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U xformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08851e9e-ee01-4e4a-a878-15b3551d5bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use a pipeline as a high-level helper\n",
    "# from transformers import pipeline\n",
    "\n",
    "# pipe = pipeline(\"text-generation\", model=\"MBZUAI/LaMini-Cerebras-590M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62881704-bd2d-41df-a56d-af3e06d76550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"MBZUAI/LaMini-Cerebras-590M\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"MBZUAI/LaMini-Cerebras-590M\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"MBZUAI/LaMini-Cerebras-111M\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"MBZUAI/LaMini-Cerebras-111M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96b47f76-c010-43ea-8010-6b2af8b67ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (4.30.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\b1\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630e0453-17ea-44d6-b0d1-8ce30df8f1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def query(payload):\n",
    "#     inputs = tokenizer(payload, return_tensors=\"pt\")\n",
    "\n",
    "#     ###model_outputs = model.generate(**inputs, max_new_tokens=5, return_dict_in_generate=True, output_scores=True)\n",
    "#     model_outputs = model.generate(**inputs,return_dict_in_generate=True, output_scores=True)\n",
    "\n",
    "#     generated_tokens_ids = model_outputs.sequences[0]\n",
    "\n",
    "#     response = tokenizer.decode(generated_tokens_ids)\n",
    "#     return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67aa427b-1175-4937-aa60-c285a2bad833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (C:/Users/b1/.cache/huggingface/datasets/timdettmers___json/timdettmers--openassistant-guanaco-6126c710748182cf/0.0.0/8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b7389345f61424fbe384e17b09f7a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"timdettmers/openassistant-guanaco\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "333963ab-310c-4522-bdc7-1e73b42647f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 9846\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 518\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8cf9aba-dc90-4308-b9cd-2f1c78b1fb58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'text': Value(dtype='string', id=None)}, post_processed=None, supervised_keys=None, task_templates=None, builder_name='json', config_name='timdettmers--openassistant-guanaco', version=0.0.0, splits={'train': SplitInfo(name='train', num_bytes=15808615, num_examples=9846, shard_lengths=None, dataset_name='json'), 'test': SplitInfo(name='test', num_bytes=839966, num_examples=518, shard_lengths=None, dataset_name='json')}, download_checksums={'https://huggingface.co/datasets/timdettmers/openassistant-guanaco/resolve/831dabac2283d99420cda0b673d7a2a43849f17a/openassistant_best_replies_train.jsonl': {'num_bytes': 20877686, 'checksum': None}, 'https://huggingface.co/datasets/timdettmers/openassistant-guanaco/resolve/831dabac2283d99420cda0b673d7a2a43849f17a/openassistant_best_replies_eval.jsonl': {'num_bytes': 1105272, 'checksum': None}}, download_size=21982958, post_processing_size=None, dataset_size=16648581, size_in_bytes=38631539)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3834fdb3-e684-4efa-9648-11eac40e3b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0736337-25bc-4776-abb9-2cd118b6ef26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9846, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d1ae15e-b67e-4c8d-abe4-65b7ec435a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50258, 768)\n",
       "    (wpe): Embedding(2048, 768)\n",
       "    (drop): Dropout(p=0.0, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-9): 10 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): GELUActivation()\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50258, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set the device to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "108535aa-bdde-4428-9127-edd752936753",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = dataset[\"train\"]\n",
    "X_test = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4207b37-f0c6-49ce-9852-fd4b8384dea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\b1\\.cache\\huggingface\\datasets\\timdettmers___json\\timdettmers--openassistant-guanaco-6126c710748182cf\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-90858038a537434d.arrow\n",
      "Loading cached processed dataset at C:\\Users\\b1\\.cache\\huggingface\\datasets\\timdettmers___json\\timdettmers--openassistant-guanaco-6126c710748182cf\\0.0.0\\8bb11242116d547c741b2e8a1f18598ffdd40a1d4f2a2872c7a28b697434bc96\\cache-ada3480ec28864ca.arrow\n"
     ]
    }
   ],
   "source": [
    "def tokenize(examples):\n",
    "    outputs = tokenizer(examples['text'], truncation=True)\n",
    "    return outputs\n",
    "\n",
    "tokenized_train_dataset = X_train.map(tokenize, batched=True)\n",
    "tokenized_test_dataset = X_test.map(tokenize, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beadbd44-397f-4ebd-bcbc-d4eeff6a0e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (4.30.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers[torch]) (3.12.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in c:\\users\\b1\\appdata\\roaming\\python\\python310\\site-packages (from transformers[torch]) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers[torch]) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers[torch]) (23.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers[torch]) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers[torch]) (2023.6.3)\n",
      "Requirement already satisfied: requests in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers[torch]) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers[torch]) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers[torch]) (4.65.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in c:\\users\\b1\\appdata\\roaming\\python\\python310\\site-packages (from transformers[torch]) (2.0.1)\n",
      "Requirement already satisfied: accelerate>=0.20.2 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from transformers[torch]) (0.22.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from requests->transformers[torch]) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from requests->transformers[torch]) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from requests->transformers[torch]) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from jinja2->torch!=1.12.0,>=1.9->transformers[torch]) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22bc597f-9393-4c00-bbc5-d55de920fcab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from accelerate) (1.25.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from accelerate) (23.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from accelerate) (5.4.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\b1\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.12.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\b1\\.conda\\envs\\tensorflow_env\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14e1b64c-0830-4cc8-9a57-fddb4e466335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "637ac00a-35bd-4a3b-8157-8cfbb79d98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef186f2d-2100-42af-b6e0-9b1064d409bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6cafc6-0613-4f18-a317-d726819422df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    pred = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, pred, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d3d05ba-66cd-4b80-8008-98bafb396763",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(num_train_epochs=1,\n",
    "                                  output_dir=\"./LLM_trainer\",\n",
    "                                  per_device_train_batch_size=16,\n",
    "                                  per_device_eval_batch_size=16,\n",
    "                                  logging_dir=\"./train_logs\",\n",
    "                                  logging_steps=500,\n",
    "                                 # save_steps=2000,\n",
    "                                  #evaluation_strategy=\"steps\",\n",
    "                                #  evaluation_strategy=\"epoch\",\n",
    "                                  eval_steps=500,\n",
    "                                  save_total_limit=2,\n",
    "                                 )\n",
    "\n",
    "trainer = Trainer(model=model,\n",
    "                  tokenizer=tokenizer,\n",
    "                  data_collator=data_collator,\n",
    "                  args=training_args,\n",
    "                  # train_dataset=tokenized_dataset[\"train\"],\n",
    "                  # eval_dataset=tokenized_dataset[\"test\"],\n",
    "                  train_dataset=tokenized_train_dataset,\n",
    "                  eval_dataset=tokenized_test_dataset,\n",
    "                  #compute_metrics=compute_metrics\n",
    "                  #compute_metrics=compute_f1\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd6d0ad-6505-41e7-a31b-637e92a49f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 10\n",
    "logging_steps = len(transcripts_encoded[\"train\"]) // batch_size\n",
    "logging_steps = 1000 // batch_size\n",
    "model_name = f\"{model_checkpoint}-finetuned-transcripts\"\n",
    "\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                 num_train_epochs=2,\n",
    "                                 learning_rate=2e-5,\n",
    "                                 per_device_train_batch_size=batch_size,\n",
    "                                 per_device_eval_batch_size=batch_size,\n",
    "                                 weight_decay=0.01,\n",
    "                                 evaluation_strategy=\"epoch\",\n",
    "                                 disable_tqdm=False,\n",
    "                                 logging_steps=logging_steps,\n",
    "                                 push_to_hub=False,\n",
    "                                 log_level=\"error\")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args,\n",
    "                 compute_metrics=compute_metrics,\n",
    "                  train_dataset=tokenized_train_dataset,\n",
    "                  eval_dataset=tokenized_test_dataset,                 tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "273e637c-d29a-4c0a-babb-5cb363075e31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\b1\\.conda\\envs\\Tensorflow_env\\lib\\site-packages\\transformers\\optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Tensorflow_env\\lib\\site-packages\\transformers\\trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1640\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[0;32m   1642\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[0;32m   1644\u001b[0m )\n\u001b[1;32m-> 1645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Tensorflow_env\\lib\\site-packages\\transformers\\trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1935\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m   1937\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m-> 1938\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1940\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   1941\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   1942\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m   1943\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   1944\u001b[0m ):\n\u001b[0;32m   1945\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   1946\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\.conda\\envs\\Tensorflow_env\\lib\\site-packages\\transformers\\trainer.py:2759\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2756\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   2758\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 2759\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   2762\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\Tensorflow_env\\lib\\site-packages\\transformers\\trainer.py:2797\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2795\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2796\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m outputs:\n\u001b[1;32m-> 2797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2798\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model did not return a loss from the inputs, only the following keys: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2799\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(outputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. For reference, the inputs it received are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(inputs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2800\u001b[0m         )\n\u001b[0;32m   2801\u001b[0m     \u001b[38;5;66;03m# We don't use .loss here since the model may return tuples instead of ModelOutput.\u001b[39;00m\n\u001b[0;32m   2802\u001b[0m     loss \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m outputs[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: The model did not return a loss from the inputs, only the following keys: logits. For reference, the inputs it received are input_ids,attention_mask."
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f9b2f2-26e5-4153-9e3d-e6cd7db2ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
