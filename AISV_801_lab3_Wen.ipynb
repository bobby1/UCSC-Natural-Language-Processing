{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bobby1/UCSC-Natural-Language-Processing/blob/main/AISV_801_lab3_Wen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aY5uyilLII__"
      },
      "source": [
        "##DBDA.X425.(12) Deep Learning and Artificial Intelligence\n",
        "Spring 2023\n",
        "# Instructor  Joseph Meyer\n",
        "Lab3: Text Classification\n",
        "\n",
        "Bobby Wen\n",
        "\n",
        "Dataset: rotten_tomatoes\n",
        "\n",
        "    1. Lemmatize text\n",
        "    \n",
        "    2. Vectorize text via bag of words or tf-idf (Remove stop words, set max_features to 500)\n",
        "    \n",
        "    3. Train test split\n",
        "    \n",
        "    4. Choose two algorithms (e.g., logistic regression and decision tree)\n",
        "    \n",
        "    5. Perform grid search on each of the algorithms\n",
        "    \n",
        "    6. Inference on test\n",
        "    \n",
        "    7. Print classification report\n",
        "    \n",
        "    8. Write out interpretation of report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vdn0JD3IJAD"
      },
      "source": [
        "# Install pre-requisits if not present already in the kernel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ7wZvl4sD8C",
        "outputId": "109b6904-a109-4430-bc14-d386b33e4b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP-9yEAvsGZV",
        "outputId": "1387f527-19bc-4c22-892f-eea29c8431de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d8_ksoKIJAG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "814c20d978244729a0ea05a4d5232a23",
            "1442045e9b1b4a37957b84edfc116385",
            "bccbb80ebb30404e84e0e1042c9c4719",
            "1cdc893fbade4486aaf8cc3cfb071114",
            "65f30cb0099141d680aa89c45097c7ae",
            "8b2c7b7d013f4d6db17fced9e544550c",
            "ef53edf71b9d45e7859872e2c0da03e3",
            "bb37290056c54272b758e2fe98215633",
            "e7543cdb8c574ffcb05c0613010deb2c",
            "4a9c5a15204940e687f1a854b9e9a5dc",
            "4606b8eec9984607a661301a438a27f0"
          ]
        },
        "id": "xLEfeeP-sIyP",
        "outputId": "ee535c93-516a-43e7-e71c-0e0b755f750d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset rotten_tomatoes (/root/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "814c20d978244729a0ea05a4d5232a23"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# #Load rotten_tomatos dataset\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"rotten_tomatoes\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br4xdzEUIJAG"
      },
      "source": [
        "# Check dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSah2wH3IJAH",
        "outputId": "5bd4b3d0-05ce-4576-e222-f7b7d03e00b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 8530\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1066\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label'],\n",
            "        num_rows: 1066\n",
            "    })\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "print (dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4P5_KXnYtcv9"
      },
      "outputs": [],
      "source": [
        "# a. Exploratory function\n",
        "#    i.Prints out\n",
        "#        1. Top n most common words\n",
        "#        2. Average text length\n",
        "#        3. Longest text length\n",
        "import nltk\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "def explore_dataset(n=10, dataset_type=\"train\"):\n",
        "    \"\"\"\n",
        "    Print descriptive information about a dataset\n",
        "\n",
        "    Args:\n",
        "        n is the number of top most common words from the dataset\n",
        "\n",
        "        dataset_type is if there are multiple data set, which one to use\n",
        "\n",
        "    Returns:\n",
        "        none\n",
        "    \"\"\"\n",
        "    # Use the the rotten_tomatoes dataset already loaded\n",
        "    reviews = dataset[dataset_type][\"text\"]\n",
        "\n",
        "    # Top n most common words\n",
        "    words = \" \".join(reviews).split()\n",
        "    word_counts = Counter(words)\n",
        "    top_words = word_counts.most_common(n)\n",
        "\n",
        "    print(f\"Top {n} most common words:\")\n",
        "    for word, count in top_words:\n",
        "        print(f\"{word}: {count}\")\n",
        "\n",
        "    # Average text length\n",
        "    total_length = sum(len(review) for review in reviews)\n",
        "    average_length = total_length / len(reviews)\n",
        "    print(f\"\\nAverage text length: {average_length:.0f} characters\")\n",
        "\n",
        "    # Longest text length\n",
        "    longest_text = max(reviews, key=len)\n",
        "    longest_length = len(longest_text)\n",
        "    print(f\"Longest text length: {longest_length} characters\")\n",
        "    print (f\"Longest text\", longest_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UWrfvyvIJAI",
        "outputId": "e148e277-15e0-4f71-b13b-63190d407281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 most common words:\n",
            ".: 11197\n",
            "the: 8024\n",
            ",: 8001\n",
            "a: 5855\n",
            "and: 4914\n",
            "of: 4814\n",
            "to: 3415\n",
            "is: 2700\n",
            "in: 2111\n",
            "that: 1974\n",
            "it: 1799\n",
            "as: 1407\n",
            "but: 1322\n",
            "with: 1271\n",
            "this: 1184\n",
            "\n",
            "Average text length: 114 characters\n",
            "Longest text length: 267 characters\n",
            "Longest text . . . spiced with humor ( 'i speak fluent flatula , ' advises denlopp after a rather , er , bubbly exchange with an alien deckhand ) and witty updatings ( silver's parrot has been replaced with morph , a cute alien creature who mimics everyone and everything around )\n"
          ]
        }
      ],
      "source": [
        "# Let's explore the data from the default training data set\n",
        "explore_dataset(n=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69Q1j9tSIJAI",
        "outputId": "050117a1-e708-4e4b-e5b8-76393728479e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 15 most common words:\n",
            ".: 1411\n",
            "the: 1046\n",
            ",: 1021\n",
            "a: 725\n",
            "and: 627\n",
            "of: 596\n",
            "to: 421\n",
            "is: 343\n",
            "in: 274\n",
            "it: 243\n",
            "that: 237\n",
            "as: 203\n",
            "but: 160\n",
            "its: 147\n",
            "for: 144\n",
            "\n",
            "Average text length: 116 characters\n",
            "Longest text length: 261 characters\n",
            "Longest text this is a children's film in the truest sense . it's packed with adventure and a worthwhile environmental message , so it's great for the kids . parents , on the other hand , will be ahead of the plot at all times , and there isn't enough clever innuendo to fil\n"
          ]
        }
      ],
      "source": [
        "# Let's explore the data from the test data set\n",
        "explore_dataset(n=15,dataset_type=\"test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIi0eoiOIJAI"
      },
      "outputs": [],
      "source": [
        "# Let's explore the data from the validation data set\n",
        "#explore_dataset(n=5,dataset_type=\"validation\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po-FnKklIJAJ"
      },
      "source": [
        "3. Train test split\n",
        "\n",
        "Load the individual data splits to be able to run the train test split\n",
        "the train and test could be loaded directly from the data splits but we would be able to show the train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fLKTSF6IJAJ"
      },
      "outputs": [],
      "source": [
        "# Using the train_test_split function, we are able to create training and testing data set from a single data set\n",
        "X_train, X_test, y_train, y_test = train_test_split(dataset[\"train\"]['text'], dataset[\"train\"]['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdTbUEA3IJAJ",
        "outputId": "0dd89ab9-74a6-497d-9688-162285b0e598"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in training data set: 6397\n",
            "Number of rows in training label set: 6397\n"
          ]
        }
      ],
      "source": [
        "# Check of number of rows in the new training data set\n",
        "print (\"Number of rows in training data set:\", len(X_train))\n",
        "print (\"Number of rows in training label set:\", len(y_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi8DSisDIJAJ",
        "outputId": "78119bbe-d144-475b-a227-11bb085c0806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in testing data set: 2133\n",
            "Number of rows in testing label set: 2133\n"
          ]
        }
      ],
      "source": [
        "# Check of number of rows in the new testing data set\n",
        "print (\"Number of rows in testing data set:\", len(X_test))\n",
        "print (\"Number of rows in testing label set:\", len(y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhGoN3kHIJAJ",
        "outputId": "4fb998ee-de8a-4ea4-bde3-cae395836147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scarlet diva has a voyeuristic tug , but all in all it's a lot less sensational than it wants to be .\n"
          ]
        }
      ],
      "source": [
        "# Check of the training dataset to make sure we it still contains valid data\n",
        "print(X_train[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V22r8i8xIJAK",
        "outputId": "f30aa96f-fda7-4ede-d246-51ff8fa99189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ],
      "source": [
        "# Check of the training dataset to make sure we it still contains valid data\n",
        "print(y_train[4])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Lemmatize text"
      ],
      "metadata": {
        "id": "kq7yUKjwNoJX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3bvR8MfIJAK",
        "outputId": "dfd30892-ff79-4915-aaad-e2551ac80664"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize the lemmatizer\n",
        "lemmatizer = nltk.WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize the array of text\n",
        "def lemmatize_text(text):\n",
        "    return lemmatizer.lemmatize(text)\n",
        "\n",
        "# Lemmatize the array of text\n",
        "X_train = list(map(lemmatize_text, X_train))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Vectorize text via bag of words or tf-idf (Remove stop words, set max_features to 500)"
      ],
      "metadata": {
        "id": "hDVG0Pp0KV_X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Jsqk6zfIJAL",
        "outputId": "4575fb77-1ce2-4fd7-a66d-c13b445a1d66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 7912)\t0.3020312998274668\n",
            "  (0, 1107)\t0.115925612247401\n",
            "  (0, 12866)\t0.0704885378738042\n",
            "  (0, 6765)\t0.07550765814614321\n",
            "  (0, 3455)\t0.1511054634436645\n",
            "  (0, 3212)\t0.26544986818339117\n",
            "  (0, 13890)\t0.1622734819616994\n",
            "  (0, 13969)\t0.13857307861935397\n",
            "  (0, 10124)\t0.1640738044043707\n",
            "  (0, 13976)\t0.16128680668980458\n",
            "  (0, 4746)\t0.2452668466624723\n",
            "  (0, 5970)\t0.2270681140966442\n",
            "  (0, 2685)\t0.2484404711189431\n",
            "  (0, 568)\t0.0589749637004156\n",
            "  (0, 7369)\t0.3020312998274668\n",
            "  (0, 8650)\t0.12155682428892886\n",
            "  (0, 11140)\t0.26031698134500975\n",
            "  (0, 12691)\t0.10364549022785599\n",
            "  (0, 6679)\t0.1411258879603038\n",
            "  (0, 13101)\t0.27895098617497904\n",
            "  (0, 5911)\t0.2558706725224913\n",
            "  (0, 4598)\t0.20398780044415643\n",
            "  (0, 9635)\t0.3020312998274668\n",
            "  (0, 13986)\t0.16128680668980458\n",
            "  (0, 4786)\t0.09712310013893696   (0, 21084)\t1\n",
            "  (0, 66682)\t1\n",
            "  (0, 46217)\t1\n",
            "  (0, 19910)\t1\n",
            "  (0, 26416)\t1\n",
            "  (0, 63190)\t1\n",
            "  (0, 29765)\t1\n",
            "  (0, 59171)\t1\n",
            "  (0, 50955)\t1\n",
            "  (0, 41260)\t1\n",
            "  (0, 34399)\t1\n",
            "  (0, 3047)\t1\n",
            "  (0, 13521)\t1\n",
            "  (0, 26917)\t1\n",
            "  (0, 20642)\t1\n",
            "  (0, 66550)\t1\n",
            "  (0, 47913)\t1\n",
            "  (0, 66481)\t1\n",
            "  (0, 65993)\t1\n",
            "  (0, 15145)\t1\n",
            "  (0, 41814)\t1\n",
            "  (0, 57932)\t1\n",
            "  (0, 15859)\t1\n",
            "  (0, 30743)\t1\n",
            "  (0, 61548)\t1\n",
            "  (0, 7502)\t1\n"
          ]
        }
      ],
      "source": [
        "import sklearn\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "# def vectorization(dataset_name, column_name):\n",
        "#     # Load the dataset\n",
        "#     dataset = load_dataset(dataset_name)\n",
        "#     df = dataset[\"train\"]\n",
        "\n",
        "#     # Get the text data\n",
        "#     text_data = df[column_name]\n",
        "\n",
        "# Create TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Create bigram vectorizer\n",
        "bigram_vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
        "X_train_bigram = bigram_vectorizer.fit_transform(X_train)\n",
        "\n",
        "print (X_train_tfidf[0], X_train_bigram[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9vaNDbLIJAL"
      },
      "source": [
        "\n",
        "The **bag-of-words** model is a simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity.\n",
        "\n",
        "The bag-of-words model is commonly used in methods of document classification where the (frequency of) occurrence of each word is used as a feature for training a classifier.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HxSzkdDIJAM"
      },
      "outputs": [],
      "source": [
        "# Create the bag of words model\n",
        "vectorizer = CountVectorizer(stop_words='english',max_features=500)\n",
        "X_train_bag = vectorizer.fit_transform(X_train)\n",
        "X_test_bag = vectorizer.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMRvKeaLIJAM",
        "outputId": "4ff04527-3a00-4f93-acb8-3179b7f5c953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 151)\t1\n",
            "  (0, 264)\t1\n",
            "  (0, 158)\t1\n",
            "  (0, 100)\t2\n",
            "  (0, 32)\t1\n",
            "  (0, 416)\t1\n",
            "  (0, 222)\t1\n",
            "  (0, 21)\t1\n",
            "  (0, 334)\t1\n",
            "  (0, 249)\t1\n"
          ]
        }
      ],
      "source": [
        "# Check the vectorized data to make sure it is valid\n",
        "print (X_train_bag[3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKfSjB_LIJAM"
      },
      "source": [
        "4. Choose two algorithms (e.g., logistic regression and decision tree)\n",
        "\n",
        "I tried logististic regression, but could not get the grid search to work.  I am using RandomForest Classifier and  DecisionTree Classifier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGPIFw-XIJAN"
      },
      "source": [
        "**Random Forest** model standalone as check of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjeMBpndIJAN",
        "outputId": "b29ae7e6-db27-43c3-ac80-3e87c8df0a85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6586966713548992\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train the Random Forest model\n",
        "classifier = RandomForestClassifier()\n",
        "classifier.fit(X_train_bag, y_train)\n",
        "# Make predictions on the test set\n",
        "predictions = classifier.predict(X_test_bag)\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEY-Um8ZIJAN",
        "outputId": "ea2dc16c-7520-4f40-af5c-e52cf8d28600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score : 0.6586966713548992\n",
            "Precision Score : 0.6762430939226519\n",
            "Recall Score : 0.5845272206303725\n",
            "F1 Score : 0.6270491803278688\n",
            "Confusion Matrix : \n",
            "[[793 293]\n",
            " [435 612]]\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation metrics\n",
        "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
        "\n",
        "print('Accuracy Score : ' + str(accuracy_score(y_test,predictions)))\n",
        "print('Precision Score : ' + str(precision_score(y_test,predictions)))\n",
        "print('Recall Score : ' + str(recall_score(y_test,predictions)))\n",
        "print('F1 Score : ' + str(f1_score(y_test,predictions)))\n",
        "\n",
        "#Dummy Classifier Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,predictions)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrZvFXwgIJAN"
      },
      "source": [
        "**DecisionTree** model standalone as check of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pru_0Z8CIJAN",
        "outputId": "e19ee3fd-3a26-4af8-f46c-02d3fb6ee4d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6043131739334271\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train the DecisionTreeClassifier model\n",
        "classifier = DecisionTreeClassifier()\n",
        "classifier.fit(X_train_bag, y_train)\n",
        "# Make predictions on the test set\n",
        "predictions = classifier.predict(X_test_bag)\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffP8N_ZqIJAO",
        "outputId": "abcf36e3-3c2e-4dea-b3b0-5c5462799433"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score : 0.6043131739334271\n",
            "Precision Score : 0.6178861788617886\n",
            "Recall Score : 0.5081184336198663\n",
            "F1 Score : 0.5576519916142557\n",
            "Confusion Matrix : \n",
            "[[757 329]\n",
            " [515 532]]\n"
          ]
        }
      ],
      "source": [
        "# Model Evaluation metrics\n",
        "from sklearn.metrics import accuracy_score,recall_score,precision_score,f1_score\n",
        "\n",
        "print('Accuracy Score : ' + str(accuracy_score(y_test,predictions)))\n",
        "print('Precision Score : ' + str(precision_score(y_test,predictions)))\n",
        "print('Recall Score : ' + str(recall_score(y_test,predictions)))\n",
        "print('F1 Score : ' + str(f1_score(y_test,predictions)))\n",
        "\n",
        "#Dummy Classifier Confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "print('Confusion Matrix : \\n' + str(confusion_matrix(y_test,predictions)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhrbAuLgIJAO"
      },
      "source": [
        "5. Perform grid search on each of the algorithms\n",
        "# GridSearchCV #\n",
        "**Grid Search Cross Validation** is a technique to search through the best parameter values from the given set of the grid of parameters. It is a cross-validation method. the model and the parameters are required to be fed in. Best parameter values are extracted and then the predictions are made."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wCGnqqbIJAO"
      },
      "source": [
        "Logistic LogisticRegression model standalone as check of model\n",
        "\n",
        "The model **failed** to fit grid search does not provide optimized solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyNzCo13IJAO",
        "outputId": "b11ca5ad-1043-45fd-9018-8f7b7bc29e4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "30 fits failed out of a total of 60.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.67031348        nan 0.6671897         nan 0.66093237]\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#from sklearn.cross_validation import  cross_val_score\n",
        "\n",
        "# Define the hyperparameters to tune\n",
        "param_grid = {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']}\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(LogisticRegression(),param_grid,cv=10)\n",
        "#grid_search = GridSearchCV(LogisticRegression(), param_grid, cv=5)\n",
        "grid_search.fit(X_train_bag, y_train)\n",
        "\n",
        "# Get the best hyperparameters and model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_ # Make predictions on the test set using the best model predictions = best_model.predict(X_test_bow)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BVd35bvIJAP"
      },
      "source": [
        "*** Random Forest *** Classifier grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCJuNDkUIJAP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "41d20176-93d0-4d07-c7a0-e64ed2fe7216"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={'criterion': ['gini', 'entropy'],\n",
              "                         'max_depth': [4, 5, 6, 7, 8],\n",
              "                         'max_features': ['sqrt', 'log2'],\n",
              "                         'n_estimators': [200, 500]})"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [4, 5, 6, 7, 8],\n",
              "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                         &#x27;n_estimators&#x27;: [200, 500]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
              "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
              "                         &#x27;max_depth&#x27;: [4, 5, 6, 7, 8],\n",
              "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
              "                         &#x27;n_estimators&#x27;: [200, 500]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "param_grid_rf= {\n",
        "    'n_estimators': [200, 500],\n",
        "    'max_features': ['sqrt', 'log2'],\n",
        "    'max_depth' : [4,5,6,7,8],\n",
        "    'criterion' :['gini', 'entropy']\n",
        "}\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid_rf, cv= 5)\n",
        "grid_search_rf.fit(X_train_bag, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4XN1WlXIJAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91d450e8-1a98-42f0-8b08-744ec2d6284e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best: 0.670313 using {'C': 0.1, 'penalty': 'l2'}\n"
          ]
        }
      ],
      "source": [
        "print(\"Best: %f using %s\" % (grid_search.best_score_, grid_search.best_params_))\n",
        "\n",
        "# # Get the best hyperparameters and model\n",
        "# # Make predictions on the test set using the best model\n",
        "best_model_rf = grid_search.best_estimator_\n",
        "score_rf = best_model.score(X_test_bag, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bfXJDu7IJAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f02e2c-01ad-4719-e22e-6361cd95d6d0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Model Prediction: LogisticRegression(C=0.1)\n",
            "Best Model Score:  0.6694796061884669\n"
          ]
        }
      ],
      "source": [
        "print(\"Best Model Prediction:\", best_model_rf)\n",
        "print (\"Best Model Score: \", score_rf )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nwcgb8LcIJAQ"
      },
      "source": [
        "**Decision Tree** Classifier grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUbh4yrKIJAQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "### Grid Search Python Implementation\n",
        "# Define the hyperparameters to tune\n",
        "param_grid = {'criterion':['gini','entropy'],\n",
        "              'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]\n",
        "              }\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)\n",
        "grid_search.fit(X_train_bag, y_train)\n",
        "\n",
        "# Get the best hyperparameters and model\n",
        "# Make predictions on the test set using the best model\n",
        "best_params_dt = grid_search.best_params_\n",
        "best_model_dt = grid_search.best_estimator_\n",
        "score_dt = best_model.score(X_test_bag, y_test)\n",
        "predictions_dt = best_model.predict(X_test_bag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXlnRUOWIJAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e39df65-1834-4736-a534-ffe097b9f9b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier(max_depth=150)\n",
            "{'criterion': 'gini', 'max_depth': 150}\n",
            "Best Model Score:  0.6694796061884669\n"
          ]
        }
      ],
      "source": [
        "print (best_model_dt )\n",
        "print (best_params_dt )\n",
        "print (\"Best Model Score: \", score_dt )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Inference on test\n",
        "model inference is the process of using a trained model to infer a result from test or live data\n",
        "\n",
        "7. Print classification report\n",
        "A Classification report is used to measure the quality of predictions from a classification algorithm. How many predictions are True and how many are False. More specifically, True Positives, False Positives, True negatives and False Negatives are used to predict the metrics of a classification report as shown below."
      ],
      "metadata": {
        "id": "0WAZLJ6WMaBl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdgVn56VIJAZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1832d10c-9553-4e8f-b84c-bd8319a69c30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification_report \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.70      0.64      1086\n",
            "           1       0.62      0.51      0.56      1047\n",
            "\n",
            "    accuracy                           0.60      2133\n",
            "   macro avg       0.61      0.60      0.60      2133\n",
            "weighted avg       0.61      0.60      0.60      2133\n",
            "\n",
            "confusion_matrix \n",
            " [[757 329]\n",
            " [515 532]]\n"
          ]
        }
      ],
      "source": [
        "### classification report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"classification_report \\n\", classification_report(y_test, predictions))\n",
        "print(\"confusion_matrix \\n\",confusion_matrix(y_test, predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZr-RSk8IJAZ"
      },
      "source": [
        "##Classification Report##\n",
        "It is one of the performance evaluation metrics of a classification-based machine learning model. It displays your model’s precision, recall, F1 score and support. It provides a better understanding of the overall performance of our trained model. To understand the classification report of a machine learning model, you need to know all of the metrics displayed in the report. For a clear understanding, I have explained all of the metrics below so that you can easily understand the classification report of your machine learning model:\n",
        "\n",
        "**Precision**: A classification metric that measures the proportion of correctly predicted positive instances among all instances predicted as positive. It focuses on the accuracy of positive predictions and is calculated as the ratio of true positives to the sum of true positives and false positives.\n",
        "\n",
        "**Recall**: Also known as sensitivity or true positive rate, it measures the proportion of correctly predicted positive instances out of all actual positive instances. Recall emphasizes the ability of a model to correctly identify positive instances and is calculated as the ratio of true positives to the sum of true positives and false negatives.\n",
        "\n",
        "**F1 Score**: A metric that combines precision and recall into a single value to evaluate classification models. It provides a balance between precision and recall, taking into account both false positives and false negatives. F1 Score is the harmonic mean of precision and recall, and it ranges from 0 to 1, with 1 representing the best possible performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDWfNaOPIJAZ"
      },
      "source": [
        "# 8. Write out interpretation of report #  \n",
        "***The numbers may change due to the iteration or run of the model.***\n",
        "\n",
        "\n",
        "The classification reports show of the model overall system performance.  Precision is the number of times the predicted value was correct, or true positives, 58% in our model, for 0 values, and 61% of the time for 1 values. This also shows the number of false positives of the model, or 42% (1-.58).\n",
        "\n",
        "Similarly, the recall show the number of time model was correct for 0 negative values, or true negatives, 64% of the time and 58% of the time for 1 negative values, or true negatives.  These are the ratios of how well the model predicted correctly and when it was correct or wrong.\n",
        "\n",
        "F1 score is a metric that measures a model's accuracy. It combines the precision and recall scores of a model. The accuracy metric computes how many times a model made a correct prediction across the entire dataset.  F1 = 2 * (precision * recall) / (precision + recall).  \n",
        "\n",
        "Support is the number of data in the label set.\n",
        "\n",
        "Macro-averge is the mean of the score, or the sum of the scores divided by the number of calculations, or support, i.e.  for f1-score macro average is .63+.61/2 = .62\n",
        "\n",
        "The weighted average is is the score weighed by the number of sampes for the data.  i.e. for the f1 score, .60 (1056/(1056+1077) + .60 (1077/(1056+1077) = .60 The weighted average accounts for the distribution of the data.\n",
        "\n",
        "The confusion_matrix is the raw output of the data\n",
        "[[732 382]\n",
        " [469 550]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJCr1lIXIJAa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "814c20d978244729a0ea05a4d5232a23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1442045e9b1b4a37957b84edfc116385",
              "IPY_MODEL_bccbb80ebb30404e84e0e1042c9c4719",
              "IPY_MODEL_1cdc893fbade4486aaf8cc3cfb071114"
            ],
            "layout": "IPY_MODEL_65f30cb0099141d680aa89c45097c7ae"
          }
        },
        "1442045e9b1b4a37957b84edfc116385": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b2c7b7d013f4d6db17fced9e544550c",
            "placeholder": "​",
            "style": "IPY_MODEL_ef53edf71b9d45e7859872e2c0da03e3",
            "value": "100%"
          }
        },
        "bccbb80ebb30404e84e0e1042c9c4719": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb37290056c54272b758e2fe98215633",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7543cdb8c574ffcb05c0613010deb2c",
            "value": 3
          }
        },
        "1cdc893fbade4486aaf8cc3cfb071114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a9c5a15204940e687f1a854b9e9a5dc",
            "placeholder": "​",
            "style": "IPY_MODEL_4606b8eec9984607a661301a438a27f0",
            "value": " 3/3 [00:00&lt;00:00, 93.22it/s]"
          }
        },
        "65f30cb0099141d680aa89c45097c7ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b2c7b7d013f4d6db17fced9e544550c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef53edf71b9d45e7859872e2c0da03e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb37290056c54272b758e2fe98215633": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7543cdb8c574ffcb05c0613010deb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a9c5a15204940e687f1a854b9e9a5dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4606b8eec9984607a661301a438a27f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}